# Asistente para Choferes ğŸšš

## ğŸ‘¤ Autor

**Javier Castillo MillÃ¡n**  
Clave: 169589  
Proyecto desarrollado como parte de la materia de Temas Selectos de AnÃ¡lisis de Datos del ITAM 2025

## DescripciÃ³n

Este proyecto implementa un asistente virtual especializado para choferes de transporte, utilizando Azure OpenAI para proporcionar informaciÃ³n inmediata sobre normativas, reglamentos y procedimientos ante situaciones como detenciones por autoridades viales.

- El notebook funcionando se encuentra en: [assistant.ipynb](./assistant.ipynb)
- La presentaciÃ³n se encuentra en: [PresentaciÃ³n](./PresentaciÃ³n.pdf)
- El vÃ­deo se encuentra en: [VÃ­deo](./VÃ­deo.mp4)
- Para un tutorial sobre como configurar azure: [Tutorial Azure](./tutorial-azure-config.md)
- Un ejemplo de acceso a Azure de forma segura con autenticaciÃ³n: [AZURE AI FOUNDRY.ipynb](./AZURE%20AI%20FOUNDRY.ipynb)

## ğŸ“‹ Ãndice

- [Asistente para Choferes ğŸšš](#asistente-para-choferes-)
  - [ğŸ‘¤ Autor](#-autor)
  - [DescripciÃ³n](#descripciÃ³n)
  - [ğŸ“‹ Ãndice](#-Ã­ndice)
  - [ğŸ” DescripciÃ³n General](#-descripciÃ³n-general)
  - [âœ¨ Funcionalidades](#-funcionalidades)
  - [âš™ï¸ ConfiguraciÃ³n del Entorno](#ï¸-configuraciÃ³n-del-entorno)
  - [ğŸ—ï¸ Estructura del CÃ³digo](#ï¸-estructura-del-cÃ³digo)
    - [1. InicializaciÃ³n del Cliente de Azure OpenAI](#1-inicializaciÃ³n-del-cliente-de-azure-openai)
    - [2. DefiniciÃ³n del Papel del Asistente](#2-definiciÃ³n-del-papel-del-asistente)
    - [3. Funciones para Consulta y Formateo](#3-funciones-para-consulta-y-formateo)
      - [FunciÃ³n Principal de Consulta](#funciÃ³n-principal-de-consulta)
      - [Formateo de Respuestas](#formateo-de-respuestas)
  - [ğŸ”„ InteracciÃ³n con Azure Cognitive Search](#-interacciÃ³n-con-azure-cognitive-search)
  - [ğŸ”„ CreaciÃ³n de Fuente de Conocimiento en Azure AI Foundry](#-creaciÃ³n-de-fuente-de-conocimiento-en-azure-ai-foundry)
    - [1. PreparaciÃ³n de documentos](#1-preparaciÃ³n-de-documentos)
    - [2. CreaciÃ³n del Ã­ndice en Azure AI Search](#2-creaciÃ³n-del-Ã­ndice-en-azure-ai-search)
    - [3. Proceso de indexaciÃ³n](#3-proceso-de-indexaciÃ³n)
    - [4. IntegraciÃ³n con el script](#4-integraciÃ³n-con-el-script)
  - [ğŸ”’ Ventajas de Seguridad con Azure AI Services](#-ventajas-de-seguridad-con-azure-ai-services)
    - [Guardrails y Protecciones](#guardrails-y-protecciones)
    - [ConfiguraciÃ³n especÃ­fica en el proyecto](#configuraciÃ³n-especÃ­fica-en-el-proyecto)
  - [ğŸš€ Uso del Asistente](#-uso-del-asistente)
  - [ğŸ”§ PersonalizaciÃ³n](#-personalizaciÃ³n)
    - [Modificar el Papel del Asistente](#modificar-el-papel-del-asistente)
    - [ConfiguraciÃ³n del Modelo](#configuraciÃ³n-del-modelo)

## ğŸ” DescripciÃ³n General

El Asistente para Choferes es una aplicaciÃ³n Jupyter Notebook que conecta a la API de Azure OpenAI para proporcionar respuestas precisas y contextualizadas. El asistente puede:

- Responder preguntas sobre normativas de transporte
- Explicar procedimientos ante detenciones por autoridades
- Proporcionar informaciÃ³n sobre documentaciÃ³n requerida
- Citar fuentes especÃ­ficas de documentos legales

La aplicaciÃ³n utiliza una base de conocimiento indexada en Azure Cognitive Search que incluye reglamentos oficiales, manuales de procedimientos y directrices de la empresa.

## âœ¨ Funcionalidades

- **Consulta basada en contexto**: El asistente analiza documentos como "Normas de seguridad.pdf", "Instructivo de contactos.pdf" y leyes de transporte.
- **Interfaz interactiva**: Implementada con Jupyter widgets para una experiencia de usuario fluida.
- **Historial de conversaciÃ³n**: Mantiene el contexto a travÃ©s de mÃºltiples consultas.
- **Referencias a documentos**: Incluye enlaces a los documentos fuente citados.
- **EstadÃ­sticas de uso**: Muestra mÃ©tricas de tokens utilizados.

## âš™ï¸ ConfiguraciÃ³n del Entorno

El proyecto utiliza variables de entorno para las credenciales de Azure:

```python
from dotenv import load_dotenv
import os

# Cargar .env
load_dotenv()

sea_key = os.getenv("SEA_KEY")
sub_key = os.getenv("SUB_KEY")
endpoint_name = os.getenv("ENDPOINT_NAME")
deployment_name = os.getenv("DEPLOYMENT_NAME")
search_endpoint_name = os.getenv("SEARCH_ENDPOINT_NAME")
blob_sas_url_name = os.getenv("BLOB_SAS_URL_NAME")
```

Debes crear un archivo `.env` en el directorio raÃ­z con las siguientes variables:

```{env}
SEA_KEY=tu_clave_de_azure_search
SUB_KEY=tu_clave_de_suscripcion_azure
ENDPOINT_NAME=https://tu-endpoint-openai.openai.azure.com
DEPLOYMENT_NAME=tu-deployment-model
SEARCH_ENDPOINT_NAME=https://tu-endpoint-search.search.windows.net
BLOB_SAS_URL_NAME=url_con_token_sas_para_acceso_a_documentos
```

## ğŸ—ï¸ Estructura del CÃ³digo

### 1. InicializaciÃ³n del Cliente de Azure OpenAI

```python
client = AzureOpenAI(
    azure_endpoint=endpoint,
    api_key=subscription_key,
    api_version="2025-01-01-preview",
)
```

Este bloque configura el cliente que se comunicarÃ¡ con la API de Azure OpenAI, utilizando los parÃ¡metros definidos en el archivo de variables de entorno.

### 2. DefiniciÃ³n del Papel del Asistente

El archivo `role.md` contiene las instrucciones detalladas para el comportamiento del asistente. Este papel define:

- El Ã¡mbito de las preguntas que puede responder
- El proceso de validaciÃ³n Ã©tica y legal
- El formato y estilo de las respuestas
- Las fuentes de conocimiento autorizadas

### 3. Funciones para Consulta y Formateo

#### FunciÃ³n Principal de Consulta

```python
def consultar_asistente(consulta, historial=None):
    if historial is None:
        historial = [{"role": "system", "content": system_message}]
    
    # AÃ±adir la nueva consulta al historial
    historial.append({"role": "user", "content": consulta})
    
    # Generar la completaciÃ³n
    completion = client.chat.completions.create(
        model=deployment,
        messages=historial,
        max_tokens=2500,
        temperature=0.2,
        top_p=0.95,
        frequency_penalty=0,
        presence_penalty=0,
        extra_body={
          "data_sources": [{
              "type": "azure_search",
              "parameters": {
                "endpoint": search_endpoint,
                "index_name": "knowledgellmchoferes",
                "authentication": {
                  "type": "api_key",
                  "key": search_key
                },
                "query_type": "simple",
                "in_scope": True,
                "top_n_documents": 20
              }
            }]
        }
    )
    
    # AÃ±adir la respuesta al historial
    respuesta = completion.choices[0].message.content
    historial.append({"role": "assistant", "content": respuesta})
    
    return completion, historial
```

Esta funciÃ³n:

1. Mantiene el historial de la conversaciÃ³n
2. EnvÃ­a la consulta al modelo de lenguaje
3. Configura parÃ¡metros como temperatura (creatividad) y tokens mÃ¡ximos
4. Conecta a Azure Cognitive Search para obtener documentos relevantes
5. AÃ±ade la respuesta al historial de conversaciÃ³n

#### Formateo de Respuestas

```python
def generar_html_respuesta(completion):
    # Extraer el contenido de la respuesta
    content = completion.choices[0].message.content
    
    # Estandarizar las referencias en el texto [docN] -> [N]
    content = estandarizar_referencias(content)
    
    # Convertir markdown a HTML
    html_content = render_markdown(content)
    
    # Extraer las citas/fuentes utilizadas...
```

Esta funciÃ³n transforma la respuesta del modelo en HTML formateado para la interfaz, incluyendo referencias a documentos y estadÃ­sticas de uso.

## ğŸ”„ InteracciÃ³n con Azure Cognitive Search

El proyecto utiliza Azure Cognitive Search para indexar y consultar documentos relevantes:

```python
"data_sources": [{
    "type": "azure_search",
    "parameters": {
      "endpoint": search_endpoint,
      "index_name": "knowledgellmchoferes",
      "authentication": {
        "type": "api_key",
        "key": search_key
      },
      "query_type": "simple",
      "in_scope": True,
      "top_n_documents": 20
    }
  }]
```

Esta configuraciÃ³n:

- Conecta con el Ã­ndice especÃ­fico `knowledgellmchoferes`
- Utiliza autenticaciÃ³n por API key
- Configura la bÃºsqueda para recuperar hasta 20 documentos relevantes
- Habilita la recuperaciÃ³n inteligente basada en la relevancia semÃ¡ntica

El sistema utiliza el contenedor de Azure Blob Storage para almacenar los documentos originales. Cuando el asistente cita una fuente, se genera una URL con token SAS para permitir la descarga directa del documento:

```python
def generar_url_documento(filepath):
    """
    Genera una URL para descargar un documento desde el blob storage
    """
    # Escapar caracteres especiales en el nombre del archivo
    import urllib.parse
    
    # Ajustar la ruta para incluir la carpeta "documentos/"
    filepath_completo = f"documentos/{filepath}"
    filename_encoded = urllib.parse.quote(filepath_completo)
    
    # Extraer la parte de la URL base y el token SAS
    container_url = blob_sas_url.split('?')[0]  # URL del contenedor sin el token
    sas_token = blob_sas_url.split('?')[1]      # Token SAS
    
    # Construir la URL completa
    document_url = f"{container_url}/{filename_encoded}?{sas_token}"
    
    return document_url
```

Esta funciÃ³n permite que los usuarios accedan a los documentos originales directamente desde la interfaz.

## ğŸ”„ CreaciÃ³n de Fuente de Conocimiento en Azure AI Foundry

El proyecto utiliza una fuente de conocimiento creada e indexada a travÃ©s de Azure AI Foundry, siguiendo estos pasos:

### 1. PreparaciÃ³n de documentos

Los documentos de normativas, leyes y manuales se almacenan en un contenedor de Azure Blob Storage, organizados en una estructura de carpetas lÃ³gica. Esto incluye:

- Normas de seguridad.pdf
- Instructivo de contactos.pdf
- Ley de caminos, puentes y autotransporte federal.pdf
- Reglamento de trÃ¡nsito en carreteras y puentes de jurisdicciÃ³n federal.pdf

### 2. CreaciÃ³n del Ã­ndice en Azure AI Search

Para crear el Ã­ndice de conocimiento:

1. Se accede al portal de Azure AI Foundry
2. Se crea un nuevo recurso de AI Search
3. Se configura un nuevo Ã­ndice `knowledgellmchoferes` con las siguientes propiedades:
   - Campos para almacenar metadatos (tÃ­tulo, autor, fecha)
   - Campo de contenido para el texto extraÃ­do
   - Campos para referencias y citas
   - Campo para la ruta del archivo original

### 3. Proceso de indexaciÃ³n

El proceso de indexaciÃ³n incluye:

1. **ExtracciÃ³n de texto**: Los PDFs son procesados mediante reconocimiento Ã³ptico de caracteres (OCR) cuando es necesario
2. **Chunking**: Los documentos largos se dividen en fragmentos manejables (chunks)
3. **Enriquecimiento semÃ¡ntico**: Se generan embeddings vectoriales para cada chunk
4. **IndexaciÃ³n**: Los chunks procesados se almacenan en el Ã­ndice de Azure Cognitive Search

### 4. IntegraciÃ³n con el script

El script interactÃºa con la fuente de conocimiento a travÃ©s de varias capas:

```{text}
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 â”‚    â”‚                  â”‚    â”‚                   â”‚
â”‚ Azure OpenAI    â”‚â—„â”€â”€â”€â”¤ Azure AI Search  â”‚â—„â”€â”€â”€â”¤ Azure Blob Storageâ”‚
â”‚ (Procesamiento) â”‚    â”‚ (Ãndice)         â”‚    â”‚ (Documentos)      â”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    â”‚
â”‚ AplicaciÃ³n Jupyter â”‚
â”‚ (Interfaz)         â”‚
â”‚                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Cuando un usuario realiza una consulta:

1. La consulta se envÃ­a al modelo Azure OpenAI a travÃ©s de la API
2. Azure OpenAI utiliza internamente Azure AI Search para encontrar chunks relevantes
3. El modelo genera una respuesta basada en los chunks recuperados
4. La respuesta incluye referencias a los documentos originales
5. El script genera URLs con tokens SAS para acceder a los documentos en Azure Blob Storage

La configuraciÃ³n `data_sources` en el cÃ³digo permite esta interacciÃ³n fluida:

```python
"data_sources": [{
    "type": "azure_search",
    "parameters": {
      "endpoint": search_endpoint,
      "index_name": "knowledgellmchoferes",
      "authentication": {
        "type": "api_key",
        "key": search_key
      },
      "query_type": "simple",
      "in_scope": True,
      "top_n_documents": 20
    }
  }]
```

## ğŸ”’ Ventajas de Seguridad con Azure AI Services

La implementaciÃ³n del asistente en Azure AI Services proporciona importantes ventajas de seguridad y control frente a otras alternativas:

### Guardrails y Protecciones

1. **Filtrado de contenido integrado**: Azure OpenAI implementa filtros que detectan y bloquean:
   - Solicitudes de actividades ilegales
   - Intentos de obtener informaciÃ³n sensible
   - GeneraciÃ³n de contenido daÃ±ino o discriminatorio

2. **DetecciÃ³n de prompt injection**: El servicio incluye protecciones contra:
   - Intentos de jailbreak del modelo
   - Prompt leaking (extraer el prompt del sistema)
   - ManipulaciÃ³n para eludir las restricciones del sistema

3. **Control de datos y privacidad**:
   - Los datos no se utilizan para entrenar modelos
   - Cumplimiento con GDPR y otras regulaciones
   - Posibilidad de implementaciÃ³n en regiones especÃ­ficas

### ConfiguraciÃ³n especÃ­fica en el proyecto

El sistema implementa varias capas de seguridad:

1. **ValidaciÃ³n Ã©tica y legal**: El papel del asistente (definido en `role.md`) incluye instrucciones especÃ­ficas para rechazar solicitudes no Ã©ticas:

```markdown
## Primero: ValidaciÃ³n Ã‰tica y Legal
- Â¿Se solicita o promueve una acciÃ³n ilegal (sobornos, falsificaciÃ³n, evasiÃ³n)?
  - Si sÃ­, rechaza la consulta y explica que estÃ¡ prohibida por las polÃ­ticas de la empresa.
  - Si no, continÃºa.
```

2. **Control de acceso**: El uso de tokens SAS para acceder a documentos garantiza que solo los usuarios autorizados puedan ver la informaciÃ³n original.

3. **ParÃ¡metros de generaciÃ³n seguros**: La configuraciÃ³n del modelo con valores conservadores reduce la posibilidad de generaciÃ³n de respuestas problemÃ¡ticas:

```python
temperature=0.2,  # Valor bajo para respuestas mÃ¡s deterministas
top_p=0.95,
frequency_penalty=0,
presence_penalty=0,
```

4. **Aislamiento de datos**: Toda la informaciÃ³n se mantiene dentro del ecosistema de Azure, sin exposiciÃ³n a servicios de terceros.

Estas capas de protecciÃ³n hacen que la soluciÃ³n sea adecuada para entornos corporativos donde la seguridad, conformidad y control de la informaciÃ³n son prioritarios.

El proyecto implementa una interfaz interactiva utilizando widgets de Jupyter:

```python
def interfaz_interactiva_con_historial():
    # Definir el CSS para la interfaz
    css = """
    <style>
        /* Estilos para la interfaz principal */
        .app-container {
            max-width: 800px;
            margin: 0 auto;
            font-family: Arial, sans-serif;
            overflow-x: hidden;
        }
        
        /* Contenedor de conversaciÃ³n con scroll vertical */
        .conversation-scroll {
            max-height: 600px;
            overflow-y: auto;
            overflow-x: hidden;
            border: 1px solid #eaeaea;
            border-radius: 10px;
            padding: 10px;
            margin-bottom: 20px;
            background-color: #ffffff;
            width: 100%;
            max-width: 780px;
        }
        ...
```

La interfaz incluye:

- Un encabezado de aplicaciÃ³n con tÃ­tulo y descripciÃ³n
- Ãrea de conversaciÃ³n con desplazamiento vertical
- Campo de entrada de texto para preguntas
- Botones para enviar consultas y limpiar el historial
- PresentaciÃ³n de respuestas con formato mejorado

## ğŸš€ Uso del Asistente

Para usar el asistente:

1. Ejecuta todas las celdas del notebook para inicializar la interfaz
2. Escribe tu consulta en el campo de texto (por ejemplo: "Â¿QuÃ© documentos debo presentar si me detiene la Guardia Nacional?")
3. Haz clic en "Enviar Consulta"
4. Revisa la respuesta del asistente, incluyendo:
   - InformaciÃ³n detallada sobre la consulta
   - Referencias a documentos especÃ­ficos
   - Enlaces para acceder a los documentos citados

## ğŸ”§ PersonalizaciÃ³n

### Modificar el Papel del Asistente

Para cambiar el comportamiento del asistente, modifica el archivo `role.md`. Puedes ajustar:

- Fuentes de conocimiento
- Criterios de validaciÃ³n
- Estilo de respuesta
- Ejemplos de consultas aceptadas/rechazadas

### ConfiguraciÃ³n del Modelo

Para ajustar la generaciÃ³n de respuestas, modifica los parÃ¡metros en la funciÃ³n `consultar_asistente()`:

```python
completion = client.chat.completions.create(
    model=deployment,
    messages=historial,
    max_tokens=2500,  # Ajusta para respuestas mÃ¡s largas/cortas
    temperature=0.2,  # Aumenta para mÃ¡s creatividad, disminuye para mÃ¡s precisiÃ³n
    top_p=0.95,       # Controla diversidad de tokens seleccionados
    frequency_penalty=0,  # Penaliza repeticiones
    presence_penalty=0,   # Penaliza temas ya mencionados
    ...
)
```
